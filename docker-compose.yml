version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
    volumes:
      - ./data/uploads:/app/data/uploads
      - ./data/models:/app/data/models
    depends_on:
      qdrant:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - rag-network

  qdrant:
    image: qdrant/qdrant:v1.9.0
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/readyz"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - rag-network

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - rag-network
    profiles:
      - with-ollama

networks:
  rag-network:
    driver: bridge

volumes:
  qdrant_data:
  ollama_models:
